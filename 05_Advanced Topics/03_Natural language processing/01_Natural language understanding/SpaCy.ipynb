{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sample code in Python using the spaCy library for Natural Language Understanding (NLU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token:  I\n",
      "Lemma:  I\n",
      "POS:  PRON\n",
      "NER:  None\n",
      "\n",
      "Token:  love\n",
      "Lemma:  love\n",
      "POS:  VERB\n",
      "NER:  None\n",
      "\n",
      "Token:  exploring\n",
      "Lemma:  explore\n",
      "POS:  VERB\n",
      "NER:  None\n",
      "\n",
      "Token:  new\n",
      "Lemma:  new\n",
      "POS:  ADJ\n",
      "NER:  None\n",
      "\n",
      "Token:  technologies\n",
      "Lemma:  technology\n",
      "POS:  NOUN\n",
      "NER:  None\n",
      "\n",
      "Token:  and\n",
      "Lemma:  and\n",
      "POS:  CCONJ\n",
      "NER:  None\n",
      "\n",
      "Token:  building\n",
      "Lemma:  build\n",
      "POS:  VERB\n",
      "NER:  None\n",
      "\n",
      "Token:  innovative\n",
      "Lemma:  innovative\n",
      "POS:  ADJ\n",
      "NER:  None\n",
      "\n",
      "Token:  solutions\n",
      "Lemma:  solution\n",
      "POS:  NOUN\n",
      "NER:  None\n",
      "\n",
      "Token:  .\n",
      "Lemma:  .\n",
      "POS:  PUNCT\n",
      "NER:  None\n",
      "\n",
      "Number of sentences:  1\n",
      "Named Entities:\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process a text\n",
    "text = \"I love exploring new technologies and building innovative solutions.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print token-level information\n",
    "for token in doc:\n",
    "    print(\"Token: \", token.text)\n",
    "    print(\"Lemma: \", token.lemma_)\n",
    "    print(\"POS: \", token.pos_)\n",
    "    print(\"NER: \", token.ent_type_ if token.ent_type_ else \"None\")\n",
    "    print()\n",
    "\n",
    "# Perform sentence-level analysis\n",
    "sentences = list(doc.sents)\n",
    "print(\"Number of sentences: \", len(sentences))\n",
    "\n",
    "# Extract named entities\n",
    "entities = list(doc.ents)\n",
    "print(\"Named Entities:\")\n",
    "for entity in entities:\n",
    "    print(entity.text, \"-\", entity.label_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code demonstrates the basic usage of spaCy for NLU tasks. It loads the English language model, processes a given text, and provides token-level information such as token text, lemma, part-of-speech (POS) tag, and named entity recognition (NER) label. It also performs sentence-level analysis by splitting the text into sentences and extracts named entities from the processed document.\n",
    "\n",
    "You'll need to install the spaCy library and download the English language model using the following commands before running the code:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install spacy\n",
    "\n",
    "python -m spacy download en_core_web_sm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
